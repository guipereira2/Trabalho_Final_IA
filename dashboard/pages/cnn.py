# pages/cnn.py
import os
import random
import streamlit as st
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten
from keras.optimizers import Adam

import zipfile, tempfile, os, pathlib, shutil

@st.cache_resource(show_spinner=False)
def extract_zip(uploaded_zip) -> str:
    """
    Recebe um arquivo enviado pelo usu√°rio (st.file_uploader),
    extrai tudo em uma pasta tempor√°ria e devolve o caminho.
    """
    tmp_dir = tempfile.mkdtemp(prefix="cxray_")
    zip_path = pathlib.Path(tmp_dir) / "dataset.zip"
    zip_path.write_bytes(uploaded_zip.read())

    with zipfile.ZipFile(zip_path) as zf:
        zf.extractall(tmp_dir)

    # tenta localizar a pasta que cont√©m 'train/', 'test/' ou 'val/'
    for root, dirs, _ in os.walk(tmp_dir):
        if {"train", "test"}.issubset(set(dirs)):
            return root   # encontrou a raiz correta

    return tmp_dir  # fallback: devolve o diret√≥rio raiz tempor√°rio

@st.cache_resource(show_spinner=False)
def load_data(path: str, size: tuple[int, int] = (64, 64)):
    """L√™ imagens (NORMAL / PNEUMONIA), redimensiona e normaliza."""
    imgs, labels = [], []
    for split in ("train", "test"):
        for cls in ("NORMAL", "PNEUMONIA"):
            folder = os.path.join(path, split, cls)
            if not os.path.isdir(folder):
                continue
            for f in os.listdir(folder):
                img = Image.open(os.path.join(folder, f)).convert("L").resize(size)
                imgs.append(np.array(img) / 255.0)
                labels.append(0 if cls == "NORMAL" else 1)
    X = np.expand_dims(np.array(imgs, dtype="float32"), -1)
    y = np.array(labels, dtype="int8")
    return train_test_split(X, y, test_size=0.30, random_state=42)


def build_cnn(filters: int, kernel: tuple[int, int],
              dropout: float, lr: float) -> tf.keras.Model:
    """Cria e compila a CNN de acordo com os hiperpar√¢metros."""
    model = Sequential([
        Conv2D(filters, kernel, activation="relu", input_shape=(64, 64, 1)),
        MaxPooling2D(),
        Dropout(dropout),
        Flatten(),
        Dense(filters, activation="relu"),
        Dense(1, activation="sigmoid")
    ])
    model.compile(optimizer=Adam(lr), loss="binary_crossentropy",
                  metrics=["accuracy"])
    return model

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ P√°gina principal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #
def render() -> None:
    st.title("üß† Redes Convolucionais (CNN)")

    # Parte te√≥rica ------------------------------------------------------ #
    st.header("Defini√ß√£o")
    st.markdown("""
    As **redes convolucionais (CNN)** s√£o arquiteturas especializadas em
    processar dados com estrutura espacial (imagens, s√©ries temporais etc.).
    Utilizam filtros convolucionais para extrair **caracter√≠sticas locais**,
    reduzindo par√¢metros e melhorando a generaliza√ß√£o.
    """)

    st.header("Campos Receptivos Locais")
    st.markdown("""
    - C√©lulas no c√©rebro respondem a regi√µes restritas do campo visual\n
    - CNNs replicam essa ideia: cada neur√¥nio ‚Äúenxerga‚Äù apenas uma parte
      da entrada.
    """)

    st.header("Compara√ß√£o com Redes MLP")
    st.markdown("""
    - **MLPs:** conex√µes globais ‚Üí muitos par√¢metros\n
    - **CNNs:** pesos **compartilhados** em filtros locais ‚Üí modelo menor.
    """)

    st.header("Opera√ß√£o de Convolu√ß√£o")
    st.latex(r"f_{\text{out}}(x)=\sum_{k=-M}^{M} f(x-k)\,g(k)")
    st.markdown("Em 2-D aplicamos o mesmo princ√≠pio a todos os canais da imagem.")

    st.header("Camada de *Pooling*")
    st.markdown("""
    - Reduz o tamanho do *feature map*\n
    - Diminui custo computacional e adiciona **invari√¢ncia √† transla√ß√£o**.
    """)

    st.header("Stride e *Padding*")
    st.markdown("""
    - **Stride:** passo da janela convolucional (ex.: 1 ou 2)\n
    - **Padding:** preenchimento das bordas para controlar a sa√≠da.
    """)

    st.divider()

    # Formul√°rio de hiperpar√¢metros ------------------------------------- #
    with st.form("params"):
        st.subheader("Configura√ß√µes de treino")

        # 1Ô∏è‚É£ arquivo .zip (opcional)
        uploaded = st.file_uploader(
        "Enviar dataset compactado (.zip) ‚Äì use a estrutura chest_xray/*",
        type="zip"
    )

        # 2Ô∏è‚É£ caminho manual (continua dispon√≠vel)
        data_dir = st.text_input("üìÇ Pasta do dataset (opcional)", "")
        
        col1, col2, col3 = st.columns(3)
        epochs   = col1.slider("√âpocas", 1, 20, 10)
        batch    = col2.selectbox("Batch size", [16, 32, 64], index=1)
        lr       = col3.select_slider(
            "Learning rate", options=[1e-4, 5e-4, 1e-3, 5e-3],
            value=1e-3, format_func=lambda x: f"{x:.0e}"
        )

        col4, col5, col6 = st.columns(3)
        filters  = col4.number_input("N¬∫ filtros", 16, 128, 32, 16)
        kernel   = col5.selectbox("Kernel", [(3, 3), (5, 5)], index=0)
        dropout  = col6.slider("Dropout", 0.0, 0.5, 0.2, 0.05)

        submitted = st.form_submit_button("üöÇ Treinar modelo")

    # 3 Execu√ß√£o do treino ------------------------------------------------- #
    if submitted:
    # Se o usu√°rio enviou .zip, extraia primeiro
        if uploaded is not None:
            data_dir = extract_zip(uploaded)
            st.success(f"Dataset extra√≠do para {data_dir}")

        # Valida√ß√£o
        if not data_dir or not os.path.isdir(data_dir):
            st.error("√â necess√°rio fornecer um dataset via upload ou caminho v√°lido.")
        st.stop()

        X_train, X_test, y_train, y_test = load_data(data_dir)
        model = build_cnn(filters, kernel, dropout, lr)

        with st.spinner("Treinando‚Ä¶"):
            history = model.fit(
                X_train, y_train,
                validation_split=0.20,
                epochs=epochs,
                batch_size=batch,
                verbose=0
            )

        acc = model.evaluate(X_test, y_test, verbose=0)[1]
        st.success(f"Acur√°cia em teste: **{acc:.2%}**")
        #st.line_chart(history.history["val_accuracy"])

        # Previs√£o aleat√≥ria -------------------------------------------- #
        idx  = random.randrange(len(X_test))
        img  = X_test[idx]
        prob = float(model.predict(img[None, ...], verbose=0)[0, 0])
        pred = "Pneumonia" if prob > 0.5 else "Normal"
        true = "Pneumonia" if y_test[idx] else "Normal"

        colA, colB = st.columns(2)
        with colA:
            st.image(img.squeeze(), width=250, caption="Previs√£o aleat√≥ria selecionada")
        with colB:
            st.metric("Verdadeiro", true)
            st.metric("Predito",  pred)
            st.metric("Acur√°cia (global)", f"{acc:.2%}")

if __name__ == "__main__":
    st.set_page_config(page_title="CNN", page_icon="üß†", layout="wide")
    render()
